{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dcgan.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "nP_AK3iJGXgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Anime Face DCGAN\n",
        "Google Colaboratory GPU Edition\n",
        "\n",
        "For hyperparameter tuning usage\n",
        "\n",
        "## 1. Installing Google Drive API Package and authenticating"
      ]
    },
    {
      "metadata": {
        "id": "Y9imRkWM2uXt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Install the PyDrive wrapper & import libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iQG9040bGqaR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. Defining some functions to upload or download files from Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "N3Bk1dMhm8Wb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def download_from_google_drive(file_in, path_out):\n",
        "  file_list = drive.ListFile({'q': 'trashed=false'}).GetList()\n",
        "  file_id = ''\n",
        "  for file in file_list:\n",
        "    if file['title'] == file_in:\n",
        "      file_id = file['id']\n",
        "  if file_id == '':\n",
        "    raise ValueError('file not found')\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(path_out)\n",
        "  print('Download completed, %s (%s) -> %s' % (file_in, file_id, path_out))\n",
        "def upload_from_google_drive(file_out, path_in):\n",
        "  uploaded = drive.CreateFile({'title': file_out})\n",
        "  uploaded.SetContentFile(path_in)\n",
        "  uploaded.Upload()\n",
        "  print('Upload completed, %s -> %s (%s)' % (path_in, file_out, uploaded.get('id')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QhGsH5Di7YMN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def sync_result(target_dir='tf_colab'):\n",
        "  #entering root directory\n",
        "  files = drive.ListFile({'q': \"trashed=false and 'root' in parents\"}).GetList()\n",
        "  root_file = None\n",
        "  weight_dir = global_var.get('weight_dir')\n",
        "  log_dir = global_var.get('log_dir')\n",
        "  output_dir = global_var.get('output_dir')\n",
        "  for file in files:\n",
        "    if file['title'] == target_dir:\n",
        "      root_file = file\n",
        "      break\n",
        "  if root_file == None:\n",
        "    raise ValueError('ID for target_dir not found')\n",
        "  #creating new directories\n",
        "  def create_dir(dir_name, overwrite=False):\n",
        "    remote_files = drive.ListFile({'q': \"trashed=false and '%s' in parents\" % root_file['id']}).GetList()\n",
        "    for x in remote_files:\n",
        "      if x['title'] != dir_name:\n",
        "        continue\n",
        "      if overwrite:\n",
        "        deleted = drive.CreateFile({'id': x['id']})\n",
        "        deleted.Trash()\n",
        "        print('directory %s deleted' % dir_name)\n",
        "      else:\n",
        "        #print('directory %s has already existed, ignored' % dir_name)\n",
        "        return x\n",
        "    meta = {'title': dir_name, 'mimeType': 'application/vnd.google-apps.folder',\n",
        "            'parents': [{'id': root_file['id']}]}\n",
        "    dir_info = drive.CreateFile(meta)\n",
        "    dir_info.Upload()\n",
        "    print('directory %s created' % dir_name)\n",
        "    return dir_info\n",
        "  weight_dir_info = create_dir(weight_dir, True)\n",
        "  log_dir_info = create_dir(log_dir)            \n",
        "  output_dir_info = create_dir(output_dir)\n",
        "  #listing the local files\n",
        "  def upload_dir(dir_name, parent_id, overwrite=False):\n",
        "    files = os.listdir(dir_name)\n",
        "    remote_files = drive.ListFile({'q': \"trashed=false and '%s' in parents\" % parent_id}).GetList()\n",
        "    remote_files = [x['title'] for x in remote_files]\n",
        "    for file in files:\n",
        "      if overwrite == False and file in remote_files:\n",
        "        #print('file %s has already existed, ignored' % file)\n",
        "        continue\n",
        "      uploaded = drive.CreateFile({'title': file, 'parents': [{'id': parent_id}]})\n",
        "      uploaded.SetContentFile(os.path.join(dir_name, file))\n",
        "      uploaded.Upload()\n",
        "      print('file %s uploaded' % file)\n",
        "  upload_dir(weight_dir, weight_dir_info['id'], True)\n",
        "  upload_dir(log_dir, log_dir_info['id'], False)\n",
        "  upload_dir(output_dir, output_dir_info['id'], False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bg-QJPHPG-Ku",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Here is the code from [Anime Face GAN](https://github.com/qhgz2013/ml-experiment)\n",
        "The following code defines DCGAN model in tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "zoRo2VYW3sTg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q tqdm\n",
        "import os\n",
        "import math\n",
        "import re\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "#from getch import getch\n",
        "\n",
        "\n",
        "# a class to store variables in a dictionary\n",
        "class Vars(object):\n",
        "    def __init__(self):\n",
        "        self.d = dict()\n",
        "\n",
        "    def get(self, key):\n",
        "        return self.d[key]\n",
        "\n",
        "    def set(self, key, value):\n",
        "        self.d[key] = value\n",
        "\n",
        "    def __iter__(self):\n",
        "        for x in self.d:\n",
        "            yield x\n",
        "\n",
        "\n",
        "global_var = Vars()\n",
        "\n",
        "\n",
        "def load_training_set():\n",
        "    input_path = global_var.get('training_set_path')\n",
        "    if not os.path.exists(input_path):\n",
        "        os.mkdir(input_path)\n",
        "    cache_path = os.path.join(input_path, '../train.npy')\n",
        "    if os.path.exists(cache_path):\n",
        "        return np.load(cache_path)\n",
        "    files = os.listdir(input_path)\n",
        "    list_images = []\n",
        "    for file in files:\n",
        "        abs_path = os.path.join(input_path, file)\n",
        "        if os.path.isfile(abs_path):\n",
        "            image = io.imread(abs_path)\n",
        "            list_images.append(image)\n",
        "    ret_tensor = np.array(list_images)\n",
        "    # rescaling data\n",
        "    ret_tensor = (ret_tensor - 127.5) / 127.5\n",
        "    ret_tensor = ret_tensor.astype(np.float32)\n",
        "    np.save(cache_path, ret_tensor)\n",
        "    return ret_tensor\n",
        "\n",
        "\n",
        "def set_vram_growth(as_default_sess=True):\n",
        "    config = tf.ConfigProto()\n",
        "    config.gpu_options.allow_growth = True\n",
        "    if as_default_sess:\n",
        "        return tf.InteractiveSession(config=config)\n",
        "    else:\n",
        "        return tf.Session(config=config)\n",
        "\n",
        "\n",
        "def rescale_to_rgb(image):\n",
        "    return (image + 1) / 2\n",
        "\n",
        "\n",
        "# tensorflow util functions\n",
        "def conv2d(i, output_dim, kernel_size=(5, 5), strides=(2, 2), stddev=0.02, name='conv2d'):\n",
        "    (k_h, k_w), (s_h, s_w) = kernel_size, strides\n",
        "    with tf.variable_scope(name):\n",
        "        w = tf.get_variable('w', [k_h, k_w, i.get_shape()[-1], output_dim],\n",
        "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "        conv = tf.nn.conv2d(i, w, strides=[1, s_h, s_w, 1], padding='SAME')\n",
        "        b = tf.get_variable('b', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "        conv = tf.nn.bias_add(conv, b)\n",
        "    return conv\n",
        "\n",
        "\n",
        "def deconv2d(i, output_shape, kernel_size=(5, 5), strides=(2, 2), stddev=0.02, name='deconv2d', output_weights=False):\n",
        "    (k_h, k_w), (s_h, s_w) = kernel_size, strides\n",
        "    with tf.variable_scope(name):\n",
        "        w = tf.get_variable('w', [k_h, k_w, output_shape[-1], i.get_shape()[-1]],\n",
        "                            initializer=tf.truncated_normal_initializer(stddev=stddev))\n",
        "        if output_shape[0]:\n",
        "            deconv = tf.nn.conv2d_transpose(i, w, output_shape=output_shape, strides=[1, s_h, s_w, 1])\n",
        "        else:\n",
        "            deconv = tf.nn.conv2d_transpose(i, w, output_shape=[tf.shape(i)[0]] + output_shape[1:],\n",
        "                                            strides=[1, s_h, s_w, 1])\n",
        "            deconv = tf.reshape(deconv, [-1] + output_shape[1:])\n",
        "        b = tf.get_variable('b', [output_shape[-1]], initializer=tf.constant_initializer(0.0))\n",
        "        deconv = tf.nn.bias_add(deconv, b)\n",
        "    if output_weights:\n",
        "        return deconv, w, b\n",
        "    else:\n",
        "        return deconv\n",
        "\n",
        "\n",
        "def leaky_relu(x, alpha=0.2, name='leaky_relu'):\n",
        "    with tf.variable_scope(name):\n",
        "        return tf.maximum(x, alpha * x)\n",
        "\n",
        "\n",
        "def dense(i, output_dim, name='linear', stddev=0.02, output_weights=False):\n",
        "    shape = i.get_shape().as_list()\n",
        "    with tf.variable_scope(name):\n",
        "        w = tf.get_variable('w', [shape[1], output_dim], initializer=tf.random_normal_initializer(stddev=stddev))\n",
        "        b = tf.get_variable('b', [output_dim], initializer=tf.constant_initializer(0.0))\n",
        "        mul = tf.matmul(i, w) + b\n",
        "    if output_weights:\n",
        "        return mul, w, b\n",
        "    else:\n",
        "        return mul\n",
        "\n",
        "\n",
        "def batch_norm(i, epsilon=1e-5, momentum=0.9, train=True, name='batch_norm'):\n",
        "    return tf.contrib.layers.batch_norm(i, decay=momentum, updates_collections=None, epsilon=epsilon, scale=True,\n",
        "                                        is_training=train, scope=name)\n",
        "\n",
        "\n",
        "def calc_conv_out_shape_same(size, stride):\n",
        "    return int(math.ceil(float(size) / float(stride)))\n",
        "\n",
        "\n",
        "def discriminator_model(input_tensor, dropout_tensor):\n",
        "    d_filter = global_var.get('d_filter')\n",
        "    d_arch = global_var.get('d_arch')\n",
        "    with tf.variable_scope('discriminator', reuse=tf.AUTO_REUSE) as scope:\n",
        "\n",
        "        # layer 1, not applying bn, uses leaky relu only\n",
        "        model = conv2d(input_tensor, d_filter, name='layer1/conv2d')\n",
        "        model = leaky_relu(model, name='layer1/lrelu')\n",
        "\n",
        "        if d_arch == 'selu':\n",
        "            def forward(inputs, name):\n",
        "                inputs = tf.nn.selu(inputs, name=name + '/selu')\n",
        "                inputs = tf.nn.dropout(inputs, dropout_tensor, name=name + '/dropout')\n",
        "                return inputs\n",
        "        elif d_arch == 'bn_first':\n",
        "            def forward(inputs, name):\n",
        "                inputs = batch_norm(inputs, name=name + '/bn')\n",
        "                inputs = leaky_relu(inputs, name=name + '/lrelu')\n",
        "                inputs = tf.nn.dropout(inputs, dropout_tensor, name=name + '/dropout')\n",
        "                return inputs\n",
        "        elif d_arch == 'bn_last':\n",
        "            def forward(inputs, name):\n",
        "                inputs = leaky_relu(inputs, name=name + '/lrelu')\n",
        "                inputs = tf.nn.dropout(inputs, dropout_tensor, name=name + '/dropout')\n",
        "                inputs = batch_norm(inputs, name=name + '/bn')\n",
        "                return inputs\n",
        "        else:\n",
        "            raise ValueError('Incorrect d_arch')\n",
        "\n",
        "        # layer 2 to 4\n",
        "        model = conv2d(model, d_filter * 2, name='layer2/conv2d')\n",
        "        model = forward(model, name='layer2')\n",
        "\n",
        "        model = conv2d(model, d_filter * 4, name='layer3/conv2d')\n",
        "        model = forward(model, name='layer3')\n",
        "\n",
        "        model = conv2d(model, d_filter * 8, name='layer4/conv2d')\n",
        "        model = forward(model, name='layer4')\n",
        "\n",
        "        model = tf.reshape(model, [tf.shape(model)[0], np.prod(model.get_shape().as_list()[1:])],\n",
        "                           name='layer5/flatten')\n",
        "        model_logits = dense(model, 1, name='layer5/dense')\n",
        "        model = tf.nn.sigmoid(model_logits, name='layer5/sigmoid')\n",
        "\n",
        "        return model, model_logits\n",
        "\n",
        "\n",
        "def generator_model(input_tensor, dropout_tensor, train=True):\n",
        "    image_width = global_var.get('image_width')\n",
        "    image_height = global_var.get('image_height')\n",
        "    g_filter = global_var.get('g_filter')\n",
        "    channel_count = global_var.get('channel_count')\n",
        "    g_arch = global_var.get('g_arch')\n",
        "    with tf.variable_scope('generator', reuse=tf.AUTO_REUSE) as scope:\n",
        "\n",
        "        if g_arch == 'selu':\n",
        "            def forward(inputs,  name):\n",
        "                inputs = tf.nn.selu(inputs, name=name + '/selu')\n",
        "                inputs = tf.nn.dropout(inputs, dropout_tensor, name=name + '/dropout')\n",
        "                return inputs\n",
        "        elif g_arch == 'bn_first':\n",
        "            def forward(inputs, name):\n",
        "                inputs = batch_norm(inputs, train=train, name=name + '/bn')\n",
        "                inputs = tf.nn.relu(inputs, name=name + '/relu')\n",
        "                inputs = tf.nn.dropout(inputs, dropout_tensor, name=name + '/dropout')\n",
        "                return inputs\n",
        "        elif g_arch == 'bn_last':\n",
        "            def forward(inputs, name):\n",
        "                inputs = tf.nn.relu(inputs, name=name + '/relu')\n",
        "                inputs = tf.nn.dropout(inputs, dropout_tensor, name=name + '/dropout')\n",
        "                inputs = batch_norm(inputs, train=train, name=name + '/bn')\n",
        "                return inputs\n",
        "        else:\n",
        "            raise ValueError('Incorrect g_arch')\n",
        "\n",
        "        # fc layer\n",
        "        size_h = calc_conv_out_shape_same(image_height, 16)\n",
        "        size_w = calc_conv_out_shape_same(image_width, 16)\n",
        "        model = dense(input_tensor, size_h * size_w * g_filter * 8, name='layer0/fc')\n",
        "        model = tf.reshape(model, [-1, size_h, size_w, g_filter * 8], name='layer0/reshape')\n",
        "        model = forward(model, name='layer0')\n",
        "\n",
        "        # deconv1\n",
        "        size_h = calc_conv_out_shape_same(image_height, 8)\n",
        "        size_w = calc_conv_out_shape_same(image_width, 8)\n",
        "        model = deconv2d(model, [None, size_h, size_w, g_filter * 4], name='layer1/deconv2d')\n",
        "        model = forward(model, name='layer1')\n",
        "\n",
        "        # deconv2\n",
        "        size_h = calc_conv_out_shape_same(image_height, 4)\n",
        "        size_w = calc_conv_out_shape_same(image_width, 4)\n",
        "        model = deconv2d(model, [None, size_h, size_w, g_filter * 2], name='layer2/deconv2d')\n",
        "        model = forward(model, name='layer2')\n",
        "\n",
        "        # deconv3\n",
        "        size_h = calc_conv_out_shape_same(image_height, 2)\n",
        "        size_w = calc_conv_out_shape_same(image_width, 2)\n",
        "        model = deconv2d(model, [None, size_h, size_w, g_filter], name='layer3/deconv2d')\n",
        "        model = forward(model, name='layer3')\n",
        "\n",
        "        # deconv4(output layer)\n",
        "        model = deconv2d(model, [None, image_height, image_width, channel_count], name='layer4/deconv2d')\n",
        "        model = tf.nn.tanh(model, name='layer4/tanh')\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "def compile_loss(d_logits, gan_logits, summary_dict):\n",
        "    d_loss_true = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits, labels=tf.ones_like(d_logits)))\n",
        "    d_loss_fake = tf.reduce_mean(\n",
        "        tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits, labels=tf.zeros_like(gan_logits)))\n",
        "    d_loss = d_loss_true + d_loss_fake\n",
        "\n",
        "    summary_dict['d_loss'] = tf.summary.scalar('d_loss', d_loss)  # test summary\n",
        "    g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=gan_logits, labels=tf.ones_like(gan_logits)))\n",
        "\n",
        "    summary_dict['g_loss'] = tf.summary.scalar('g_loss', g_loss)\n",
        "    return d_loss, g_loss\n",
        "\n",
        "\n",
        "prev_step = 0\n",
        "\n",
        "\n",
        "# this code is for saving the current weights of discriminator, generator model\n",
        "def save_model(sess, saver, fname, step, sync=False):\n",
        "    saver.save(sess, fname + '/gan', global_step=step)\n",
        "    print('\\nmodel saved, save step %d' % step)\n",
        "    if sync:\n",
        "        # Authenticate and create the PyDrive client.\n",
        "        # This only needs to be done once per notebook.\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        drive = GoogleDrive(gauth)\n",
        "        sync_result()\n",
        "    return saver\n",
        "\n",
        "\n",
        "# this code is for loading the saved weights of discriminator, generator model\n",
        "def load_model(sess, saver, fname):\n",
        "    ckpt = tf.train.get_checkpoint_state(fname)\n",
        "    if ckpt and ckpt.model_checkpoint_path:\n",
        "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
        "        global prev_step\n",
        "        prev_step = int(re.search(re.compile('\\\\d+$'), ckpt.model_checkpoint_path)[0])\n",
        "    print('\\nmodel loaded, restore step %d' % prev_step)\n",
        "    return saver\n",
        "\n",
        "\n",
        "def save_images(output_name, images):\n",
        "    m, h, w, c = images.shape\n",
        "    rows = int(math.ceil(math.sqrt(m)))\n",
        "    cols = rows\n",
        "    out_image = np.zeros((rows * h, cols * w, c))\n",
        "    for y in range(rows):\n",
        "        for x in range(cols):\n",
        "            offset = y * cols + x\n",
        "            if offset >= m:\n",
        "                continue\n",
        "            out_image[y*h:(y+1)*h, x*w:(x+1)*w, :] = images[offset]\n",
        "    io.imsave(output_name, out_image)\n",
        "\n",
        "\n",
        "def train_model(sess, saver, train_x,\n",
        "                d_opt, g_opt, sampler,\n",
        "                image_input, noise_input, sample_noise, dropout_input,\n",
        "                summary_dict, summary_writer):\n",
        "    # retrieving the global variables\n",
        "    m = train_x.shape[0]\n",
        "    batch_size = global_var.get('batch_size')\n",
        "    noise_dim = global_var.get('noise_dim')\n",
        "    dropout_rate = global_var.get('dropout_rate')\n",
        "    test_generator_per_step = global_var.get('test_generator_per_step')\n",
        "    save_weights_per_step = global_var.get('save_weights_per_step')\n",
        "    random_count = global_var.get('random_count')\n",
        "    d_opt_runs_per_step = global_var.get('d_opt_runs_per_step')\n",
        "    g_opt_runs_per_step = global_var.get('g_opt_runs_per_step')\n",
        "    epochs = global_var.get('epochs')\n",
        "\n",
        "    # updating the step counter\n",
        "    global prev_step\n",
        "    step_sum = prev_step\n",
        "    # retrieving the summary variables\n",
        "    d_loss_sum = summary_dict['d_loss']\n",
        "    g_loss_sum = summary_dict['g_loss']\n",
        "\n",
        "    d_pred = summary_dict['d_pred']\n",
        "    g_pred = summary_dict['g_pred']\n",
        "    g_trace = summary_dict['g_trace']\n",
        "    d_lr_sum = summary_dict['d_lr']\n",
        "    d_beta1_sum = summary_dict['d_beta1']\n",
        "    g_lr_sum = summary_dict['g_lr']\n",
        "    g_beta1_sum = summary_dict['g_beta1']\n",
        "    # the epoch counter (from 0 every time)\n",
        "    i = 0\n",
        "    # the counter for d_opt runs\n",
        "    d_opt_has_ran = 0\n",
        "    \n",
        "    while True:\n",
        "        i += 1\n",
        "        if epochs <= 0:\n",
        "            #if getch() == 'q':\n",
        "            #    break\n",
        "            print('\\n[Epoch %d]' % i)\n",
        "        else:\n",
        "            if i > epochs:\n",
        "                break\n",
        "            print('\\n[Epoch %d of %d]' % (i, epochs))\n",
        "\n",
        "        # randomize the indices for the training set\n",
        "        random_idx = np.arange(m)\n",
        "        np.random.shuffle(random_idx)\n",
        "        # calculating how many steps should be run for one epoch\n",
        "        steps = int(math.ceil(m / batch_size))\n",
        "        for step in tqdm(range(steps), ascii=True):\n",
        "            # summarize the learning rate\n",
        "            summary, summary2 = sess.run([d_lr_sum, d_beta1_sum])\n",
        "            summary_writer.add_summary(summary, step_sum)\n",
        "            summary_writer.add_summary(summary2, step_sum)\n",
        "            summary, summary2 = sess.run([g_lr_sum, g_beta1_sum])\n",
        "            summary_writer.add_summary(summary, step_sum)\n",
        "            summary_writer.add_summary(summary2, step_sum)\n",
        "\n",
        "            # the indices of training set for current step\n",
        "            step_idx = random_idx[step * batch_size: (step + 1) * batch_size]\n",
        "            # the sample length of current step\n",
        "            length = len(step_idx)\n",
        "            images_real = train_x[step_idx]\n",
        "            noise = np.random.uniform(-1.0, 1.0, size=[length, noise_dim])\n",
        "\n",
        "            # training the discriminator\n",
        "            _, summary, summary2 = sess.run([d_opt, d_loss_sum, d_pred], feed_dict={image_input: images_real,\n",
        "                                                                                    noise_input: noise,\n",
        "                                                                                    dropout_input: 1.0 - dropout_rate})\n",
        "            summary_writer.add_summary(summary, step_sum)\n",
        "            summary_writer.add_summary(summary2, step_sum)\n",
        "            d_opt_has_ran += 1\n",
        "            # continue to train the discriminator if d_opt_runs_per_step > 1 (skips training the generator)\n",
        "            if d_opt_has_ran < d_opt_runs_per_step:\n",
        "                continue\n",
        "            d_opt_has_ran %= d_opt_runs_per_step\n",
        "\n",
        "            for _ in range(g_opt_runs_per_step):\n",
        "                _, summary = sess.run([g_opt, g_loss_sum], feed_dict={noise_input: noise,\n",
        "                                                                      dropout_input: 1.0 - dropout_rate})\n",
        "                summary_writer.add_summary(summary, step_sum)\n",
        "\n",
        "            # testing generator\n",
        "            if (step_sum + 1) % test_generator_per_step == 0:\n",
        "                noise = np.random.uniform(-1.0, 1.0, size=[random_count, noise_dim])\n",
        "                img_pred, summary = sess.run([sampler, g_pred], feed_dict={noise_input: noise, dropout_input: 1.0})\n",
        "                summary_writer.add_summary(summary, step_sum + 1)\n",
        "                img_trace, summary = sess.run([sampler, g_trace], feed_dict={noise_input: sample_noise,\n",
        "                                                                             dropout_input: 1.0})\n",
        "                summary_writer.add_summary(summary, step_sum + 1)\n",
        "                \n",
        "                save_images(global_var.get('output_dir') + '/pred_%d_steps.png' % (step_sum + 1),\n",
        "                            rescale_to_rgb(img_pred))\n",
        "                save_images(global_var.get('output_dir') + '/trace_%d_steps.png' % (step_sum + 1),\n",
        "                            rescale_to_rgb(img_trace))\n",
        "            # saving weights\n",
        "            if (step_sum + 1) % save_weights_per_step == 0:\n",
        "                saver = save_model(sess, saver, global_var.get('weight_dir'), step_sum + 1)\n",
        "\n",
        "            step_sum += 1\n",
        "            # end step for\n",
        "        # end epoch for\n",
        "    # save model after exiting training process\n",
        "    save_model(sess, saver, global_var.get('weight_dir'), step_sum)\n",
        "    prev_step = step_sum\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-whdH0ppHltL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Pre-Training Process\n",
        "Defining all the training parameters here"
      ]
    },
    {
      "metadata": {
        "id": "jJpGBwWB3xlL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# defining the output image shape for the generator\n",
        "image_width = 100\n",
        "image_height = 100\n",
        "# defining the dimension of noise vector for the generator (also called z_dim)\n",
        "noise_dim = 100\n",
        "# defining the minimal filter size for g(generator) and d(discriminator)\n",
        "# for the DCGAN paper, the filter size is [1024, 512, 256, 128] (except the last value 3), so set this value to 128\n",
        "g_filter = 64\n",
        "d_filter = 64\n",
        "# defining the batch size for batch training\n",
        "batch_size = 128\n",
        "# defining the file path for loading the training set\n",
        "training_set_path = 'train'\n",
        "# defining the image color channel count (for default only, will be overwritten after loading the training set)\n",
        "channel_count = 3\n",
        "# defining the learning rate and momentum value for Adam optimizer\n",
        "d_adam_lr = 0.0005\n",
        "d_adam_beta1 = 0.5\n",
        "g_adam_lr = 0.0002\n",
        "g_adam_beta1 = 0.5\n",
        "# defining the number used to generate the image during the training process\n",
        "# `random_count` is used to generate images with random noise\n",
        "# `sample_count` is used to generate images with fixed noise\n",
        "random_count = 64\n",
        "sample_count = 64\n",
        "# defining the dropout rate for the learning process, set it to 0.0 to disable dropout layer\n",
        "dropout_rate = 0.0\n",
        "# defining how many training steps the generator should be tested\n",
        "test_generator_per_step = 100\n",
        "# defining how many training steps the weights should be saved\n",
        "save_weights_per_step = 500\n",
        "# defining how many times discriminator and generator optimizer should run in one training step\n",
        "d_opt_runs_per_step = 1\n",
        "g_opt_runs_per_step = 1\n",
        "# defining the directory for storing model weights, the logs and generator outputs\n",
        "weight_dir = 'model.run2'\n",
        "log_dir = 'log.run2'\n",
        "output_dir = 'output.run2'\n",
        "# defining the architecture of D and G\n",
        "# `selu` uses the SeLU activation function (Self-normalized Linear Unit), only followed by a dropout layer\n",
        "# `bn_first` uses ReLU activation for G and LeakyReLU for D, ordered by (De)Conv2D -> BN -> Activation -> Dropout\n",
        "# `bn_last` uses ReLU activation for G and LeakyReLU for G, ordered by (De)Conv2D -> Activation -> Dropout -> BN\n",
        "d_arch = 'bn_first'\n",
        "g_arch = 'bn_first'\n",
        "# epochs for training, set it to -1 if you want to exit the program by pressing `Q`\n",
        "epochs = 50\n",
        "\n",
        "# save to global variables\n",
        "global_var.set('image_width', image_width)\n",
        "global_var.set('image_height', image_height)\n",
        "global_var.set('noise_dim', noise_dim)\n",
        "global_var.set('g_filter', g_filter)\n",
        "global_var.set('d_filter', d_filter)\n",
        "global_var.set('batch_size', batch_size)\n",
        "global_var.set('training_set_path', training_set_path)\n",
        "global_var.set('channel_count', channel_count)\n",
        "global_var.set('d_adam_lr', d_adam_lr)\n",
        "global_var.set('d_adam_beta1', d_adam_beta1)\n",
        "global_var.set('g_adam_lr', g_adam_lr)\n",
        "global_var.set('g_adam_beta1', g_adam_beta1)\n",
        "global_var.set('random_count', random_count)\n",
        "global_var.set('sample_count', sample_count)\n",
        "global_var.set('dropout_rate', dropout_rate)\n",
        "global_var.set('test_generator_per_step', test_generator_per_step)\n",
        "global_var.set('save_weights_per_step', save_weights_per_step)\n",
        "global_var.set('d_opt_runs_per_step', d_opt_runs_per_step)\n",
        "global_var.set('g_opt_runs_per_step', g_opt_runs_per_step)\n",
        "global_var.set('weight_dir', weight_dir)\n",
        "global_var.set('log_dir', log_dir)\n",
        "global_var.set('output_dir', output_dir)\n",
        "global_var.set('d_arch', d_arch)\n",
        "global_var.set('g_arch', g_arch)\n",
        "global_var.set('epochs', epochs)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8Cj8I3b4_6x",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Retrieving data and cleaning up working directories\n",
        "cleaning up the local working directories, then retrieving training set and model weights from Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "QDxJyO4I5FHJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 30
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "209c10e7-094f-4d48-a1e4-81ea2378cbf0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521730126224,
          "user_tz": -480,
          "elapsed": 40781,
          "user": {
            "displayName": "qhgz2011@hotmail.com",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111469927240443201404"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "if not os.path.exists('train.npy'):\n",
        "  download_from_google_drive('train.npy','train.npy')\n",
        "def cleaning_up_weight_dir():\n",
        "  weight_dir = global_var.get('weight_dir')\n",
        "  if not os.path.exists(weight_dir):\n",
        "    return\n",
        "  files = os.listdir(weight_dir)\n",
        "  training_steps = {}\n",
        "  for file in files:\n",
        "    step = re.search(re.compile('.*?(\\\\d+)\\\\..*'), file)\n",
        "    if step is None:\n",
        "      continue\n",
        "    step = step[1]\n",
        "    training_steps[int(step)] = None\n",
        "  training_steps = list(training_steps.keys())\n",
        "  training_steps.sort()\n",
        "  training_steps = training_steps[-5:]\n",
        "  for file in files:\n",
        "    step = re.search(re.compile('.*?(\\\\d+)\\\\..*'), file)\n",
        "    if step is None:\n",
        "      continue\n",
        "    step = step[1]\n",
        "    if int(step) not in training_steps:\n",
        "      path = os.path.join(weight_dir, file)\n",
        "      print('removing %s' % path)\n",
        "      os.remove(path)\n",
        "def retrieve_model(root_dir='tf_colab'):\n",
        "  root_files = drive.ListFile({'q':\"trashed=false and 'root' in parents\"}).GetList()\n",
        "  root_info = None\n",
        "  for file in root_files:\n",
        "    if file['title'] == root_dir:\n",
        "      root_info = file\n",
        "      break\n",
        "  if root_info is None:\n",
        "    raise ValueError('root_dir not found')\n",
        "  model_dir = global_var.get('weight_dir')\n",
        "  model_files = drive.ListFile({'q': \"trashed=false and '%s' in parents\" % root_info['id']}).GetList()\n",
        "  model_info = None\n",
        "  for file in model_files:\n",
        "    if file['title'] == model_dir:\n",
        "      model_info = file\n",
        "      break\n",
        "  if not os.path.exists(weight_dir):\n",
        "    os.mkdir(weight_dir)\n",
        "  if model_info is None:\n",
        "    #raise ValueError('weight_dir not found')\n",
        "    print('weight_dir not found, ignored')\n",
        "    return\n",
        "  model_files = drive.ListFile({'q': \"trashed=false and '%s' in parents\" % model_info['id']}).GetList()\n",
        "  for file in model_files:\n",
        "    downloaded = drive.CreateFile({'id': file['id']})\n",
        "    downloaded.GetContentFile(os.path.join(weight_dir, file['title']))\n",
        "    print('downloaded', file['title'])\n",
        "retrieve_model()\n",
        "cleaning_up_weight_dir()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloaded checkpoint\n",
            "downloaded gan-34000.data-00000-of-00001\n",
            "downloaded gan-34000.index\n",
            "downloaded gan-31000.data-00000-of-00001\n",
            "downloaded gan-34500.index\n",
            "downloaded gan-35000.meta\n",
            "downloaded gan-31000.meta\n",
            "downloaded gan-31100.data-00000-of-00001\n",
            "downloaded gan-35000.index\n",
            "downloaded gan-34500.data-00000-of-00001\n",
            "downloaded gan-30500.index\n",
            "downloaded gan-34500.meta\n",
            "downloaded gan-29500.data-00000-of-00001\n",
            "downloaded gan-31100.meta\n",
            "downloaded gan-35500.meta\n",
            "downloaded gan-33500.index\n",
            "downloaded gan-29500.index\n",
            "downloaded gan-30000.index\n",
            "downloaded gan-35500.data-00000-of-00001\n",
            "downloaded gan-33500.data-00000-of-00001\n",
            "downloaded gan-30500.data-00000-of-00001\n",
            "downloaded gan-29500.meta\n",
            "downloaded gan-35500.index\n",
            "downloaded gan-33500.meta\n",
            "downloaded gan-31100.index\n",
            "downloaded gan-34000.meta\n",
            "downloaded gan-30000.meta\n",
            "downloaded gan-31000.index\n",
            "downloaded gan-30500.meta\n",
            "downloaded gan-30000.data-00000-of-00001\n",
            "downloaded gan-35000.data-00000-of-00001\n",
            "removing model.run2/gan-30000.data-00000-of-00001\n",
            "removing model.run2/gan-30500.meta\n",
            "removing model.run2/gan-31000.index\n",
            "removing model.run2/gan-30000.meta\n",
            "removing model.run2/gan-31100.index\n",
            "removing model.run2/gan-29500.meta\n",
            "removing model.run2/gan-30500.data-00000-of-00001\n",
            "removing model.run2/gan-30000.index\n",
            "removing model.run2/gan-29500.index\n",
            "removing model.run2/gan-31100.meta\n",
            "removing model.run2/gan-29500.data-00000-of-00001\n",
            "removing model.run2/gan-30500.index\n",
            "removing model.run2/gan-31100.data-00000-of-00001\n",
            "removing model.run2/gan-31000.meta\n",
            "removing model.run2/gan-31000.data-00000-of-00001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZzgylgV19Nw8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "constructing graph and optimizer. **BE AWARE**: run it only once, otherwise it will raise an exception"
      ]
    },
    {
      "metadata": {
        "id": "FNTSI0Pgsx_7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 2
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "outputId": "bea2b9e9-39e9-4c2a-bedd-bccf779becb6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521722817339,
          "user_tz": -480,
          "elapsed": 3764,
          "user": {
            "displayName": "qhgz2011@hotmail.com",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111469927240443201404"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# validation test for architecture string\n",
        "if d_arch not in ['selu', 'bn_first', 'bn_last']:\n",
        "    raise ValueError('d_arch should be one of \"selu\", \"bn_first\" or \"bn_last\"')\n",
        "if g_arch not in ['selu', 'bn_first', 'bn_last']:\n",
        "    raise ValueError('g_arch should be one of \"selu\", \"bn_first\" or \"bn_last\"')\n",
        "\n",
        "# loading the training set into train_x, updating the channel_count\n",
        "print('** LOADING TRAINING SET **')\n",
        "train_x = load_training_set()\n",
        "channel_count = train_x.shape[-1]\n",
        "global_var.set('channel_count', channel_count)\n",
        "print(train_x.shape, train_x.dtype)\n",
        "\n",
        "# constructing the graph\n",
        "print('** CONSTRUCTING VARIABLES AND COMPUTE GRAPH **')\n",
        "image_input = tf.placeholder(tf.float32, [None, image_height, image_width, channel_count],\n",
        "                             name='discriminator/input')\n",
        "noise_input = tf.placeholder(tf.float32, [None, noise_dim], name='generator/input')\n",
        "dropout_input = tf.placeholder(tf.float32, name='dropout_rate')\n",
        "summary_dict = dict()\n",
        "\n",
        "d, d_logits = discriminator_model(image_input, dropout_input)\n",
        "g = generator_model(noise_input, dropout_input)\n",
        "gan, gan_logits = discriminator_model(g, dropout_input)\n",
        "sampler = generator_model(noise_input, dropout_input, train=False)\n",
        "\n",
        "# generating the loss function\n",
        "d_loss, g_loss = compile_loss(d_logits, gan_logits, summary_dict)\n",
        "t_vars = tf.trainable_variables()\n",
        "d_vars = [var for var in t_vars if 'discriminator' in var.name]\n",
        "g_vars = [var for var in t_vars if 'generator' in var.name]\n",
        "d_opt = tf.train.AdamOptimizer(d_adam_lr, beta1=d_adam_beta1).minimize(d_loss, var_list=d_vars)\n",
        "g_opt = tf.train.AdamOptimizer(g_adam_lr, beta1=g_adam_beta1).minimize(g_loss, var_list=g_vars)\n",
        "\n",
        "tf.contrib.slim.model_analyzer.analyze_vars(t_vars, print_info=True)\n",
        "\n",
        "# set the sample noise using the specified seed\n",
        "np.random.seed(0)\n",
        "sample_noise = np.random.uniform(-1.0, 1.0, size=[sample_count, noise_dim])\n",
        "import time\n",
        "\n",
        "t = int(time.time())\n",
        "np.random.seed(t)\n",
        "\n",
        "summary_dict['d_pred'] = tf.summary.histogram('d_pred', tf.reshape(tf.concat([d, gan], axis=0), [1, -1]))\n",
        "summary_dict['g_pred'] = tf.summary.image('g_pred', g, max_outputs=random_count)\n",
        "summary_dict['g_trace'] = tf.summary.image('g_trace', g, max_outputs=sample_count)\n",
        "summary_dict['d_lr'] = tf.summary.scalar('d_lr', d_adam_lr)\n",
        "summary_dict['d_beta1'] = tf.summary.scalar('d_beta1', d_adam_beta1)\n",
        "summary_dict['g_lr'] = tf.summary.scalar('g_lr', g_adam_lr)\n",
        "summary_dict['g_beta1'] = tf.summary.scalar('g_beta1', g_adam_beta1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** LOADING TRAINING SET **\n",
            "(5619, 100, 100, 3) float32\n",
            "** CONSTRUCTING VARIABLES AND COMPUTE GRAPH **\n",
            "---------\n",
            "Variables: name (type shape) [size]\n",
            "---------\n",
            "discriminator/layer1/conv2d/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
            "discriminator/layer1/conv2d/b:0 (float32_ref 64) [64, bytes: 256]\n",
            "discriminator/layer2/conv2d/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
            "discriminator/layer2/conv2d/b:0 (float32_ref 128) [128, bytes: 512]\n",
            "discriminator/layer2/bn/beta:0 (float32_ref 128) [128, bytes: 512]\n",
            "discriminator/layer2/bn/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
            "discriminator/layer3/conv2d/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
            "discriminator/layer3/conv2d/b:0 (float32_ref 256) [256, bytes: 1024]\n",
            "discriminator/layer3/bn/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
            "discriminator/layer3/bn/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
            "discriminator/layer4/conv2d/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
            "discriminator/layer4/conv2d/b:0 (float32_ref 512) [512, bytes: 2048]\n",
            "discriminator/layer4/bn/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
            "discriminator/layer4/bn/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
            "discriminator/layer5/dense/w:0 (float32_ref 25088x1) [25088, bytes: 100352]\n",
            "discriminator/layer5/dense/b:0 (float32_ref 1) [1, bytes: 4]\n",
            "generator/layer0/fc/w:0 (float32_ref 100x25088) [2508800, bytes: 10035200]\n",
            "generator/layer0/fc/b:0 (float32_ref 25088) [25088, bytes: 100352]\n",
            "generator/layer0/bn/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
            "generator/layer0/bn/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
            "generator/layer1/deconv2d/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]\n",
            "generator/layer1/deconv2d/b:0 (float32_ref 256) [256, bytes: 1024]\n",
            "generator/layer1/bn/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
            "generator/layer1/bn/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
            "generator/layer2/deconv2d/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]\n",
            "generator/layer2/deconv2d/b:0 (float32_ref 128) [128, bytes: 512]\n",
            "generator/layer2/bn/beta:0 (float32_ref 128) [128, bytes: 512]\n",
            "generator/layer2/bn/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
            "generator/layer3/deconv2d/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]\n",
            "generator/layer3/deconv2d/b:0 (float32_ref 64) [64, bytes: 256]\n",
            "generator/layer3/bn/beta:0 (float32_ref 64) [64, bytes: 256]\n",
            "generator/layer3/bn/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
            "generator/layer4/deconv2d/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]\n",
            "generator/layer4/deconv2d/b:0 (float32_ref 3) [3, bytes: 12]\n",
            "Total size of variables: 11175300\n",
            "Total bytes of variables: 44701200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ISPH0blh9bZx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "starting the gpu session here, re-run the following cell if you closed the session"
      ]
    },
    {
      "metadata": {
        "id": "osxRvdRnrPvA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b79303d-773a-4011-b408-54ace7c0f766",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521730136097,
          "user_tz": -480,
          "elapsed": 1648,
          "user": {
            "displayName": "qhgz2011@hotmail.com",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111469927240443201404"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# starting the session\n",
        "print(\"** STARTING SESSION **\")\n",
        "saver = tf.train.Saver()\n",
        "sess = set_vram_growth()\n",
        "tf.global_variables_initializer().run(session=sess)\n",
        "summary_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
        "\n",
        "# creating new directory\n",
        "if not os.path.exists(log_dir):\n",
        "    os.mkdir(log_dir)\n",
        "if not os.path.exists(weight_dir):\n",
        "    os.mkdir(weight_dir)\n",
        "if not os.path.exists(output_dir):\n",
        "    os.mkdir(output_dir)\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "** STARTING SESSION **\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G1YNUBw7Hzj5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6. In-Training Process\n",
        "Here is the code for loading existed model, training model and saving current model\n",
        "\n",
        "If the session started, you can run this cell repeatly whatever you want"
      ]
    },
    {
      "metadata": {
        "id": "NJRQSdZW4C0F",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m6lmS7Y06xP7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            },
            {
              "item_id": 2
            },
            {
              "item_id": 3
            },
            {
              "item_id": 47
            },
            {
              "item_id": 48
            },
            {
              "item_id": 89
            },
            {
              "item_id": 90
            },
            {
              "item_id": 126
            },
            {
              "item_id": 127
            },
            {
              "item_id": 166
            },
            {
              "item_id": 167
            },
            {
              "item_id": 208
            },
            {
              "item_id": 209
            },
            {
              "item_id": 253
            },
            {
              "item_id": 254
            },
            {
              "item_id": 297
            },
            {
              "item_id": 298
            },
            {
              "item_id": 343
            },
            {
              "item_id": 344
            },
            {
              "item_id": 387
            },
            {
              "item_id": 388
            },
            {
              "item_id": 433
            },
            {
              "item_id": 434
            },
            {
              "item_id": 477
            },
            {
              "item_id": 478
            },
            {
              "item_id": 493
            },
            {
              "item_id": 494
            },
            {
              "item_id": 523
            },
            {
              "item_id": 524
            },
            {
              "item_id": 569
            },
            {
              "item_id": 570
            },
            {
              "item_id": 615
            },
            {
              "item_id": 616
            },
            {
              "item_id": 661
            },
            {
              "item_id": 662
            },
            {
              "item_id": 707
            },
            {
              "item_id": 708
            },
            {
              "item_id": 753
            },
            {
              "item_id": 754
            },
            {
              "item_id": 799
            },
            {
              "item_id": 800
            },
            {
              "item_id": 845
            },
            {
              "item_id": 846
            },
            {
              "item_id": 891
            },
            {
              "item_id": 892
            },
            {
              "item_id": 937
            },
            {
              "item_id": 938
            },
            {
              "item_id": 983
            },
            {
              "item_id": 984
            },
            {
              "item_id": 1016
            },
            {
              "item_id": 1017
            },
            {
              "item_id": 1029
            },
            {
              "item_id": 1030
            },
            {
              "item_id": 1075
            },
            {
              "item_id": 1076
            },
            {
              "item_id": 1121
            },
            {
              "item_id": 1122
            },
            {
              "item_id": 1134
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 1513
        },
        "outputId": "6e778576-d669-4a96-a043-d87e3345b1aa"
      },
      "cell_type": "code",
      "source": [
        "saver = load_model(sess, saver, weight_dir)\n",
        "\n",
        "# start training process\n",
        "print('** TRAINING PROCESS STARTED **')\n",
        "if epochs <= 0:\n",
        "    print('Press \"Q\" to exit this program')\n",
        "\n",
        "train_model(sess, saver, train_x, d_opt, g_opt, sampler, image_input, noise_input, sample_noise, dropout_input,\n",
        "            summary_dict, summary_writer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model.run2/gan-35500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model loaded, restore step 35500\n",
            "** TRAINING PROCESS STARTED **\n",
            "\n",
            "[Epoch 1 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.49s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 2 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 3 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25%|##5       | 11/44 [00:16<00:49,  1.49s/it]/usr/local/lib/python3.6/dist-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
            "  .format(dtypeobj_in, dtypeobj_out))\n",
            "100%|##########| 44/44 [01:06<00:00,  1.51s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 4 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 5 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.51s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 6 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 7 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.51s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 8 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 9 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 10 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.50s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 11 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 12 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 36%|###6      | 16/44 [00:25<00:43,  1.57s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model saved, save step 36000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.51s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 13 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 14 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.50s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 15 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 16 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.50s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 17 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 18 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 19 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.50s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 20 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 21 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.50s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 22 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 23 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73%|#######2  | 32/44 [00:48<00:18,  1.52s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "model saved, save step 36500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.51s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 24 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:05<00:00,  1.48s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 25 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|##########| 44/44 [01:06<00:00,  1.50s/it]\n",
            "  0%|          | 0/44 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 26 of 50]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 27%|##7       | 12/44 [00:17<00:47,  1.49s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "aiLwyc4pIJQJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 7. Post-Training Process\n",
        "Closing the session and file handles, releasing all used resources"
      ]
    },
    {
      "metadata": {
        "id": "-_o3-DiB4_F8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "sess.close()\n",
        "summary_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J_uoIsJbIWfA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 8. Sync the training data to your Google Drive\n",
        "sync the model weights, summary logs, and the output images to you Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "nZ6Y-lq-7azp",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 64
            },
            {
              "item_id": 111
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 2091
        },
        "outputId": "8e90873c-1f77-49f7-be16-5e8cf56bd2c4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521729682386,
          "user_tz": -480,
          "elapsed": 288463,
          "user": {
            "displayName": "qhgz2011@hotmail.com",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111469927240443201404"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "sync_result()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "directory model.run2 deleted\n",
            "directory model.run2 created\n",
            "file gan-35000.data-00000-of-00001 uploaded\n",
            "file gan-30000.data-00000-of-00001 uploaded\n",
            "file gan-30500.meta uploaded\n",
            "file gan-31000.index uploaded\n",
            "file gan-30000.meta uploaded\n",
            "file gan-34000.meta uploaded\n",
            "file gan-31100.index uploaded\n",
            "file gan-33500.meta uploaded\n",
            "file gan-35500.index uploaded\n",
            "file gan-29500.meta uploaded\n",
            "file gan-30500.data-00000-of-00001 uploaded\n",
            "file gan-33500.data-00000-of-00001 uploaded\n",
            "file gan-35500.data-00000-of-00001 uploaded\n",
            "file gan-30000.index uploaded\n",
            "file gan-29500.index uploaded\n",
            "file gan-33500.index uploaded\n",
            "file gan-35500.meta uploaded\n",
            "file gan-31100.meta uploaded\n",
            "file gan-29500.data-00000-of-00001 uploaded\n",
            "file gan-34500.meta uploaded\n",
            "file gan-30500.index uploaded\n",
            "file gan-34500.data-00000-of-00001 uploaded\n",
            "file gan-35000.index uploaded\n",
            "file gan-31100.data-00000-of-00001 uploaded\n",
            "file gan-31000.meta uploaded\n",
            "file gan-35000.meta uploaded\n",
            "file gan-34500.index uploaded\n",
            "file gan-31000.data-00000-of-00001 uploaded\n",
            "file gan-34000.index uploaded\n",
            "file gan-34000.data-00000-of-00001 uploaded\n",
            "file checkpoint uploaded\n",
            "file events.out.tfevents.1521722819.b0b87e9b50b1 uploaded\n",
            "file pred_34600_steps.png uploaded\n",
            "file pred_33700_steps.png uploaded\n",
            "file trace_33600_steps.png uploaded\n",
            "file pred_32300_steps.png uploaded\n",
            "file trace_34500_steps.png uploaded\n",
            "file trace_33700_steps.png uploaded\n",
            "file pred_31200_steps.png uploaded\n",
            "file trace_33300_steps.png uploaded\n",
            "file trace_34400_steps.png uploaded\n",
            "file trace_31400_steps.png uploaded\n",
            "file trace_33400_steps.png uploaded\n",
            "file pred_33300_steps.png uploaded\n",
            "file pred_34900_steps.png uploaded\n",
            "file trace_32000_steps.png uploaded\n",
            "file trace_32100_steps.png uploaded\n",
            "file pred_32000_steps.png uploaded\n",
            "file trace_35400_steps.png uploaded\n",
            "file trace_34200_steps.png uploaded\n",
            "file pred_31400_steps.png uploaded\n",
            "file pred_33800_steps.png uploaded\n",
            "file pred_33500_steps.png uploaded\n",
            "file trace_34300_steps.png uploaded\n",
            "file pred_34700_steps.png uploaded\n",
            "file pred_35400_steps.png uploaded\n",
            "file trace_32300_steps.png uploaded\n",
            "file trace_35100_steps.png uploaded\n",
            "file pred_32100_steps.png uploaded\n",
            "file pred_32200_steps.png uploaded\n",
            "file trace_33200_steps.png uploaded\n",
            "file pred_33100_steps.png uploaded\n",
            "file trace_34700_steps.png uploaded\n",
            "file pred_33600_steps.png uploaded\n",
            "file pred_35200_steps.png uploaded\n",
            "file pred_33900_steps.png uploaded\n",
            "file trace_32700_steps.png uploaded\n",
            "file trace_34800_steps.png uploaded\n",
            "file trace_33900_steps.png uploaded\n",
            "file pred_33400_steps.png uploaded\n",
            "file pred_35100_steps.png uploaded\n",
            "file pred_34100_steps.png uploaded\n",
            "file pred_35300_steps.png uploaded\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "file trace_34000_steps.png uploaded\n",
            "file pred_31600_steps.png uploaded\n",
            "file pred_31800_steps.png uploaded\n",
            "file trace_31900_steps.png uploaded\n",
            "file trace_33500_steps.png uploaded\n",
            "file trace_31600_steps.png uploaded\n",
            "file trace_32900_steps.png uploaded\n",
            "file pred_32800_steps.png uploaded\n",
            "file pred_32700_steps.png uploaded\n",
            "file trace_35000_steps.png uploaded\n",
            "file pred_35500_steps.png uploaded\n",
            "file pred_31700_steps.png uploaded\n",
            "file trace_35500_steps.png uploaded\n",
            "file pred_33000_steps.png uploaded\n",
            "file pred_34500_steps.png uploaded\n",
            "file trace_34100_steps.png uploaded\n",
            "file trace_34600_steps.png uploaded\n",
            "file trace_33800_steps.png uploaded\n",
            "file pred_34000_steps.png uploaded\n",
            "file trace_33100_steps.png uploaded\n",
            "file pred_31900_steps.png uploaded\n",
            "file pred_31300_steps.png uploaded\n",
            "file pred_35000_steps.png uploaded\n",
            "file trace_31500_steps.png uploaded\n",
            "file pred_34400_steps.png uploaded\n",
            "file trace_31200_steps.png uploaded\n",
            "file pred_34300_steps.png uploaded\n",
            "file trace_32400_steps.png uploaded\n",
            "file trace_32500_steps.png uploaded\n",
            "file pred_31500_steps.png uploaded\n",
            "file trace_35300_steps.png uploaded\n",
            "file pred_32500_steps.png uploaded\n",
            "file trace_35200_steps.png uploaded\n",
            "file trace_31300_steps.png uploaded\n",
            "file pred_32400_steps.png uploaded\n",
            "file trace_32800_steps.png uploaded\n",
            "file pred_34800_steps.png uploaded\n",
            "file trace_32200_steps.png uploaded\n",
            "file pred_32600_steps.png uploaded\n",
            "file trace_32600_steps.png uploaded\n",
            "file trace_33000_steps.png uploaded\n",
            "file pred_33200_steps.png uploaded\n",
            "file pred_32900_steps.png uploaded\n",
            "file pred_34200_steps.png uploaded\n",
            "file trace_31700_steps.png uploaded\n",
            "file trace_34900_steps.png uploaded\n",
            "file trace_31800_steps.png uploaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qkZ4FuH31c6c",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "b46201d3-0ad2-4d3e-b5b5-3bb9a372cb8f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1521729683918,
          "user_tz": -480,
          "elapsed": 1506,
          "user": {
            "displayName": "qhgz2011@hotmail.com",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "111469927240443201404"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!rm -rf *.run2\n",
        "#!rm train.npy\n",
        "!ls -s\n",
        "!ls -s model.run2"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 658504\r\n",
            "     4 datalab\t      4 model.run2        4 train\r\n",
            "     4 log.run2       4 output.run2  658484 train.npy\n",
            "total 1316944\n",
            "     4 checkpoint\t\t      130976 gan-33500.data-00000-of-00001\n",
            "130976 gan-29500.data-00000-of-00001       8 gan-33500.index\n",
            "     8 gan-29500.index\t\t         664 gan-33500.meta\n",
            "   756 gan-29500.meta\t\t      130976 gan-34000.data-00000-of-00001\n",
            "130976 gan-30000.data-00000-of-00001       8 gan-34000.index\n",
            "     8 gan-30000.index\t\t         664 gan-34000.meta\n",
            "   756 gan-30000.meta\t\t      130976 gan-34500.data-00000-of-00001\n",
            "130976 gan-30500.data-00000-of-00001       8 gan-34500.index\n",
            "     8 gan-30500.index\t\t         664 gan-34500.meta\n",
            "   756 gan-30500.meta\t\t      130976 gan-35000.data-00000-of-00001\n",
            "130976 gan-31000.data-00000-of-00001       8 gan-35000.index\n",
            "     8 gan-31000.index\t\t         664 gan-35000.meta\n",
            "   756 gan-31000.meta\t\t      130976 gan-35500.data-00000-of-00001\n",
            "130976 gan-31100.data-00000-of-00001       8 gan-35500.index\n",
            "     8 gan-31100.index\t\t         664 gan-35500.meta\n",
            "   756 gan-31100.meta\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rr1CL3o_My5E",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hDdUdAXG8OOu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}