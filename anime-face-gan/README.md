# Anime DCGAN model in tensorflow

Code reference: [carpedm20/DCGAN-tensorflow](https://github.com/carpedm20/DCGAN-tensorflow)

Original paper: [here](https://arxiv.org/abs/1511.06434)

## Training set

We do not upload the training set, all the images can be crawled from [pixiv](https://www.pixiv.net/),
[twitter](https://twitter.com/) or other websites.

The training set we use has only 5619 samples, with different art styles.

We use the anime face detection from [here](https://github.com/nagadomi/lbpcascade_animeface), to use the following
code, just put the `lbpcascade_animeface.xml` 
([here](https://github.com/nagadomi/lbpcascade_animeface/blob/master/lbpcascade_animeface.xml) for downloading) into
root directory of this repository and run the following python code:

For single process version:
```python
from build_training_set import build_training_set
# dest_res defines the width and height of output images
build_training_set('D:/the path contains the images', 'D:/the path for output images', dest_res=100)
```

For multi process version:
```python
from build_training_set_v2 import build_training_set_v2
# process_count defines how many processes should be run in parallel, set to None so it can create the processes depending your CPU cores
build_training_set_v2('D:/the path contains the images', 'D:/the path for output images', dest_res=100, process_count=None)
```

## Current status

We are tuning the hyper parameters, the hyper parameters for different runs can be found in [run.txt](run.txt), a model
will be trained after 50k steps for each run.

## View different results

All the images generated by generator are listed in [this file](result.md)